name: Run Nextflow Pipeline on AWS

on:
  workflow_dispatch:
    inputs:
      profile:
        description: 'Nextflow profile to use (only custom available)'
        required: true
        default: 'custom'
        type: choice
        options:
        - custom
      input_s3_path:
        description: 'S3 path to input FASTQ files (samples only)'
        required: true
        default: 's3://bp-wgs-covaris-input-data/samples'
      reference_s3_path:
        description: 'S3 path to reference FASTA'
        required: true
        default: 's3://bp-wgs-covaris-input-data/reference/GCA_000001405.15_GRCh38_genomic.fna'
      known_sites:
        description: 'Comma-separated S3 paths to known sites VCF files'
        required: true
        default: 's3://bp-wgs-covaris-input-data/reference/known_sites/Homo_sapiens_assembly38.dbsnp138.vcf.gz, s3://bp-wgs-covaris-input-data/reference/known_sites/Homo_sapiens_assembly38.dbsnp138.vcf.gz.tbi'
      output_s3_path:
        description: 'S3 path for results'
        required: true
        default: 's3://bp-wgs-covaris-nextflow-results/results'
      aws_region:
        description: 'AWS region (e.g., us-east-1, us-east-2, eu-west-1)'
        required: true
        default: 'us-east-2'
      nextflow_version:
        description: 'Nextflow version to use'
        required: false
        default: '23.10.1'

jobs:
  run-nextflow:
    runs-on: ubuntu-latest

    permissions:
      id-token: write
      contents: read

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ github.event.inputs.aws_region }}

      - name: Setup Java
        uses: actions/setup-java@v4
        with:
          distribution: 'corretto'
          java-version: '17'

      - name: Install Nextflow
        run: |
          wget -qO- https://get.nextflow.io | bash -s -- -version ${{ github.event.inputs.nextflow_version }}
          sudo mv nextflow /usr/local/bin/
          chmod +x /usr/local/bin/nextflow

      - name: Validate AWS setup
        run: |
          aws sts get-caller-identity
          aws batch describe-compute-environments --region ${{ github.event.inputs.aws_region }}

      - name: Debug S3 input files
        run: |
          echo "Listing contents of input S3 bucket: ${{ github.event.inputs.input_s3_path }}"
          
          # Check if it's a public AWS bucket requiring anonymous access
          if [[ "${{ github.event.inputs.input_s3_path }}" == *"gatk-test-data"* ]] || [[ "${{ github.event.inputs.input_s3_path }}" == *"broad-references"* ]]; then
            echo "Detected public AWS dataset - using anonymous access (--no-sign-request)"
            aws s3 ls ${{ github.event.inputs.input_s3_path }}/ --recursive --no-sign-request
            echo ""
            echo "Looking specifically for fastq files:"
            aws s3 ls ${{ github.event.inputs.input_s3_path }}/ --recursive --no-sign-request | grep -E "\.(fastq|fq)" || echo "No FASTQ files found"
            echo ""
            echo "Total file count:"
            aws s3 ls ${{ github.event.inputs.input_s3_path }}/ --recursive --no-sign-request | wc -l
          else
            echo "Using authenticated access for private bucket"
            aws s3 ls ${{ github.event.inputs.input_s3_path }}/ --recursive
            echo ""
            echo "Looking specifically for fastq files:"
            aws s3 ls ${{ github.event.inputs.input_s3_path }}/ --recursive | grep -E "\.(fastq|fq)\.?g?z?$" || echo "No FASTQ files found"
            echo ""
            echo "Total file count:"
            aws s3 ls ${{ github.event.inputs.input_s3_path }}/ --recursive | wc -l
          fi

      - name: Debug Nextflow parameters
        run: |
          echo "Profile: '${{ github.event.inputs.profile }}'"
          echo "Input S3 path: '${{ github.event.inputs.input_s3_path }}'"
          echo "Reference S3 path: '${{ github.event.inputs.reference_s3_path }}'"
          echo "Known sites: '${{ github.event.inputs.known_sites }}'"
          echo "Output S3 path: '${{ github.event.inputs.output_s3_path }}'"
          echo "AWS region: '${{ github.event.inputs.aws_region }}'"
          echo "Nextflow version: '${{ github.event.inputs.nextflow_version }}'"

      - name: Confirm S3 access is working
        run: |
          echo "S3 access already confirmed in previous steps - skipping complex test script"

      # Download previous Nextflow metadata for resume functionality
      - name: Download Nextflow metadata from S3
        run: |
          echo "Attempting to download previous Nextflow metadata for resume..."
          aws s3 sync s3://bp-wgs-covaris-nextflow-workdir/metadata/.nextflow/ .nextflow/ --quiet || echo "No previous metadata found - starting fresh"
          
      # Fusion / Wave integration
      - name: Export Seqera/Tower Token
        run: echo "TOWER_ACCESS_TOKEN=${{ secrets.TOWER_ACCESS_TOKEN }}" >> $GITHUB_ENV

      - name: Build Nextflow command
        id: build_cmd
        run: |
          # Base command with profile
          BASE_CMD="nextflow run main.nf -profile aws,${{ github.event.inputs.profile }}"
          
          # Always add input_dir and outdir
          BASE_CMD="$BASE_CMD --input_dir \"${{ github.event.inputs.input_s3_path }}\""
          BASE_CMD="$BASE_CMD --outdir \"${{ github.event.inputs.output_s3_path }}\""
          BASE_CMD="$BASE_CMD --aws_region \"${{ github.event.inputs.aws_region }}\""
          
          # Add required reference and known_sites parameters
          BASE_CMD="$BASE_CMD --reference \"${{ github.event.inputs.reference_s3_path }}\""
          BASE_CMD="$BASE_CMD --known_sites \"${{ github.event.inputs.known_sites }}\""
          
          # Add reporting options and resume
          FULL_CMD="$BASE_CMD -resume -with-report nextflow_report.html -with-timeline timeline.html -with-dag flowchart.html -with-fusion"
          
          echo "NEXTFLOW_CMD=$FULL_CMD" >> $GITHUB_OUTPUT
          echo "Built command: $FULL_CMD"

      - name: Run Nextflow pipeline (with Fusion)
        run: |
          echo "About to run Nextflow command:"
          echo "${{ steps.build_cmd.outputs.NEXTFLOW_CMD }}"
          echo ""
          
          ${{ steps.build_cmd.outputs.NEXTFLOW_CMD }}

      - name: Upload Nextflow metadata to S3 for resume
        if: always()
        run: |
          echo "Uploading Nextflow metadata to S3 for future resume..."
          aws s3 sync .nextflow/ s3://bp-wgs-covaris-nextflow-workdir/metadata/.nextflow/ --quiet || echo "Failed to upload metadata"

      - name: Upload Nextflow reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: nextflow-reports
          path: |
            nextflow_report.html
            timeline.html
            flowchart.html
            .nextflow.log

      - name: Cleanup local files
        if: always()
        run: |
          echo "Cleaning up local files only (S3 metadata preserved)..."
          rm -rf work/ .nextflow*
